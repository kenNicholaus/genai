{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dR8YC8psyZya"
      },
      "outputs": [],
      "source": [
        "!pip install \"shapely<2.0.0\"\n",
        "!pip install google-cloud-aiplatform --upgrade\n",
        "!pip install langchain\n",
        "!pip install ipympl plot-utils matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "id": "pYn0BWjQynLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "PROJECT_ID = ! gcloud config get-value project\n",
        "PROJECT_ID = PROJECT_ID[0]\n",
        "LOCATION = \"us-central1\" # @param {type:\"string\"}\n",
        "\n",
        "# define project information manually if the above code didn't work\n",
        "if PROJECT_ID == \"(unset)\":\n",
        "  PROJECT_ID = \"[your-project-id]\" # @param {type:\"string\"}\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")\n"
      ],
      "metadata": {
        "id": "fhextIUkrf2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from vertexai.language_models import TextEmbeddingModel\n",
        "\n",
        "embedding_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")\n",
        "\n",
        "embeddings = embedding_model.get_embeddings([\"Python\"])\n",
        "\n",
        "vector = embeddings[0].values\n",
        "print(f\"Length = {len(vector)}\")\n",
        "print(vector)"
      ],
      "metadata": {
        "id": "w9RshbzlyzH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = embedding_model.get_embeddings([\"Python\", \"Java\",\n",
        "                                             \"BASIC\", \"COBOL\",\n",
        "                                             \"JavaScript\", \"Lisp\"])\n",
        "\n",
        "for embedding in embeddings:\n",
        "  vector = embedding.values\n",
        "  print(vector)"
      ],
      "metadata": {
        "id": "8sGGuCZvy4d3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = embedding_model.get_embeddings([\"\"\"Text embedding is an important NLP\n",
        "      technique that converts textual data into numerical vectors that can be processed\n",
        "      by machine learning algorithms, especially large models. These vector\n",
        "      representations are designed to capture the semantic meaning and context\n",
        "      of the words they represent.\"\"\"])\n",
        "\n",
        "\n",
        "for embedding in embeddings:\n",
        "  vector = embedding.values\n",
        "  print(vector)"
      ],
      "metadata": {
        "id": "aBeujIhXzBo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "emb_1 = embedding_model.get_embeddings(['Python is a great programming language..'])\n",
        "emb_2 = embedding_model.get_embeddings(['JavaScript is my favorite great programming.'])\n",
        "emb_3 = embedding_model.get_embeddings(['The dog chased that car.'])\n",
        "\n",
        "print(cosine_similarity([emb_1[0].values],[emb_2[0].values]))\n",
        "print(cosine_similarity([emb_2[0].values],[emb_3[0].values]))\n",
        "print(cosine_similarity([emb_1[0].values],[emb_3[0].values]))"
      ],
      "metadata": {
        "id": "YPDwqEiBz4vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_1 = \"Missing flamingo discovered at swimming pool\"\n",
        "in_2 = \"Sea otter spotted on surfboard by beach\"\n",
        "in_3 = \"Baby panda enjoys boat ride\"\n",
        "in_4 = \"Breakfast themed food truck beloved by all!\"\n",
        "in_5 = \"New curry restaurant aims to please!\"\n",
        "in_6 = \"Python developers are wonderful people\"\n",
        "in_7 = \"TypeScript, C++ or Java? All are great!\"\n",
        "\n",
        "input_text_lst_news = [in_1, in_2, in_3, in_4, in_5, in_6, in_7]\n",
        "\n",
        "embeddings = []\n",
        "for input_text in input_text_lst_news:\n",
        "    emb = embedding_model.get_embeddings(\n",
        "        [input_text])[0].values\n",
        "    embeddings.append(emb)\n"
      ],
      "metadata": {
        "id": "3gFvRk3_1KOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "embeddings_array = np.array(embeddings)\n",
        "print(\"Shape: \" + str(embeddings_array.shape))\n",
        "print(embeddings_array)"
      ],
      "metadata": {
        "id": "gdZieDf_1aRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Perform PCA for 2D visualization\n",
        "PCA_model = PCA(n_components = 2)\n",
        "PCA_model.fit(embeddings_array)\n",
        "new_values = PCA_model.transform(embeddings_array)\n",
        "\n",
        "\n",
        "print(\"Shape: \" + str(new_values.shape))\n",
        "print(new_values)"
      ],
      "metadata": {
        "id": "3_ONK8It1k75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.DataFrame({ 'x':new_values[:,0],\n",
        "                      'y':new_values[:,1],\n",
        "                      'sentences': input_text_lst_news})\n",
        "\n",
        "# Create a visualization\n",
        "sns.relplot(data, x='x', y='y',\n",
        "    kind='scatter', hue='sentences'\n",
        ")"
      ],
      "metadata": {
        "id": "lVFU9aA-2DaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Embeddings with LangChain"
      ],
      "metadata": {
        "id": "lEh4zxZ724y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "\n",
        "input_array = [\n",
        "        \"Missing flamingo discovered at swimming pool\",\n",
        "        \"Sea otter spotted on surfboard by beach\",\n",
        "        \"Baby panda enjoys boat ride\",\n",
        "        \"Breakfast themed food truck beloved by all!\",\n",
        "        \"Hello World!\",\n",
        "        \"New curry restaurant aims to please!\",\n",
        "        \"Python developers are wonderful people\",\n",
        "        \"TypeScript, C++ or Java? All are great!\"\n",
        "\n",
        "    ]\n",
        "\n",
        "embedding_langchain_model=VertexAIEmbeddings()\n",
        "embeddings = embedding_langchain_model.embed_documents(input_array)\n",
        "\n",
        "print(len(embeddings), len(embeddings[0]))\n",
        "print(embeddings[0])\n"
      ],
      "metadata": {
        "id": "59fQmsIC24cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rate Limiting Embeddings Class"
      ],
      "metadata": {
        "id": "ZadXwZMk7JhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.llms import VertexAI\n",
        "from langchain.pydantic_v1 import BaseModel\n",
        "from typing import List\n",
        "import time\n",
        "\n",
        "# Utility functions for Embeddings API with rate limiting\n",
        "def rate_limit(max_per_minute):\n",
        "    period = 60 / max_per_minute\n",
        "    print(\"Waiting\")\n",
        "    while True:\n",
        "        before = time.time()\n",
        "        yield\n",
        "        after = time.time()\n",
        "        elapsed = after - before\n",
        "        sleep_time = max(0, period - elapsed)\n",
        "        if sleep_time > 0:\n",
        "            print(\".\", end=\"\")\n",
        "            time.sleep(sleep_time)\n",
        "\n",
        "class CustomVertexAIEmbeddings(VertexAIEmbeddings, BaseModel):\n",
        "    requests_per_minute: int\n",
        "    num_instances_per_batch: int\n",
        "\n",
        "    # Overriding embed_documents method\n",
        "    def embed_documents(self, texts: List[str]):\n",
        "        limiter = rate_limit(self.requests_per_minute)\n",
        "        results = []\n",
        "        docs = list(texts)\n",
        "\n",
        "        while docs:\n",
        "            # Working in batches because the API accepts maximum 5\n",
        "            # documents per request to get embeddings\n",
        "            head, docs = (\n",
        "                docs[: self.num_instances_per_batch],\n",
        "                docs[self.num_instances_per_batch :],\n",
        "            )\n",
        "            chunk = self.client.get_embeddings(head)\n",
        "            results.extend(chunk)\n",
        "            next(limiter)\n",
        "\n",
        "        return [r.values for r in results]\n"
      ],
      "metadata": {
        "id": "e0CGfIs-7Qwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding\n",
        "EMBEDDING_QPM = 100\n",
        "EMBEDDING_NUM_BATCH = 5\n",
        "\n",
        "embedding_langchain_model = CustomVertexAIEmbeddings(\n",
        "    requests_per_minute=EMBEDDING_QPM,\n",
        "    num_instances_per_batch=EMBEDDING_NUM_BATCH,\n",
        ")\n",
        "\n",
        "embeddings = embedding_langchain_model.embed_documents(input_array)\n",
        "print(len(embeddings), len(embeddings[0]))\n",
        "print(embeddings[0])"
      ],
      "metadata": {
        "id": "Cliww4167f-t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}