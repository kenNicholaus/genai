{
  "cells": [
    {
      "cell_type": "code",
      "id": "HjuNybcFNVtkZi5KPWfqC78m",
      "metadata": {
        "tags": [],
        "id": "HjuNybcFNVtkZi5KPWfqC78m"
      },
      "source": [
        "!pip install \"shapely<2.0.0\"\n",
        "!pip install google-cloud-aiplatform --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "id": "ANUh74xiSubY"
      },
      "id": "ANUh74xiSubY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "PROJECT_ID = ! gcloud config get-value project\n",
        "PROJECT_ID = PROJECT_ID[0]\n",
        "LOCATION = \"us-central1\" # @param {type:\"string\"}\n",
        "\n",
        "# define project information manually if the above code didn't work\n",
        "if PROJECT_ID == \"(unset)\":\n",
        "  PROJECT_ID = \"[your-project-id]\" # @param {type:\"string\"}\n",
        "\n",
        "print(PROJECT_ID)\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")\n"
      ],
      "metadata": {
        "id": "2gpJ29BYS6Wn"
      },
      "id": "2gpJ29BYS6Wn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PaLM Prompt"
      ],
      "metadata": {
        "id": "0qaQYdDpVDyJ"
      },
      "id": "0qaQYdDpVDyJ"
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.language_models import TextGenerationModel\n",
        "\n",
        "parameters = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"max_output_tokens\": 1024,\n",
        "    \"temperature\": 0.9,\n",
        "    \"top_p\": 1\n",
        "}\n",
        "model = TextGenerationModel.from_pretrained(\"text-bison\")\n",
        "response = model.predict(\n",
        "    \"\"\"Who was Grace Hopper\"\"\",\n",
        "    **parameters\n",
        ")\n",
        "print(f\"Response from Model: {response.text}\")"
      ],
      "metadata": {
        "id": "gjcrABXsT24i"
      },
      "id": "gjcrABXsT24i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PaLM Streaming"
      ],
      "metadata": {
        "id": "yyaX5eDJVQ56"
      },
      "id": "yyaX5eDJVQ56"
    },
    {
      "cell_type": "code",
      "source": [
        "responses = model.predict_streaming(\"Tell me about Steve Jobs\",**parameters)\n",
        "\n",
        "for response in responses:\n",
        "        print(response.text)"
      ],
      "metadata": {
        "id": "gc3W2hzuVTZi"
      },
      "id": "gc3W2hzuVTZi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PaLM Chat"
      ],
      "metadata": {
        "id": "IcKv4UdRVuuh"
      },
      "id": "IcKv4UdRVuuh"
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.language_models import ChatModel, InputOutputTextPair\n",
        "\n",
        "parameters = {\n",
        "    \"max_output_tokens\": 1024,\n",
        "    \"temperature\": 0.9,\n",
        "    \"top_p\": 1\n",
        "}\n",
        "chat_model = ChatModel.from_pretrained(\"chat-bison\")\n",
        "\n",
        "chat = chat_model.start_chat(\n",
        "    context=\"\"\"\"\"\",\n",
        ")\n",
        "\n",
        "response = chat.send_message(\"\"\"Who was Steve Jobs\"\"\", **parameters)\n",
        "print(f\"Response from Model: {response.text}\")"
      ],
      "metadata": {
        "id": "NyDyIr5hVxx_"
      },
      "id": "NyDyIr5hVxx_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\"\"\"Did he have any children?\"\"\", **parameters)\n",
        "print(f\"Response from Model: {response.text}\")"
      ],
      "metadata": {
        "id": "Z5mOuHuLWPdr"
      },
      "id": "Z5mOuHuLWPdr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat.message_history)"
      ],
      "metadata": {
        "id": "wcKC_KpXWW6C"
      },
      "id": "wcKC_KpXWW6C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Streaming Chat"
      ],
      "metadata": {
        "id": "_eVDtQGRWiip"
      },
      "id": "_eVDtQGRWiip"
    },
    {
      "cell_type": "code",
      "source": [
        "chat = chat_model.start_chat()\n",
        "\n",
        "parameters = {\n",
        "    \"max_output_tokens\": 1024,\n",
        "    \"temperature\": 0.9,\n",
        "    \"top_p\": 1\n",
        "}\n",
        "responses = chat.send_message_streaming(\"\"\"Hi\"\"\", **parameters)\n",
        "for response in responses:\n",
        "        print(response.text)"
      ],
      "metadata": {
        "id": "Ekt78EAIWiGW"
      },
      "id": "Ekt78EAIWiGW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responses = chat.send_message_streaming(\"\"\"Tell me about Grace Hopper\"\"\", **parameters)\n",
        "for response in responses:\n",
        "        print(response.text)"
      ],
      "metadata": {
        "id": "LkKql84RXMCB"
      },
      "id": "LkKql84RXMCB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responses = chat.send_message_streaming(\"\"\"List some key dates in her life\"\"\", **parameters)\n",
        "for response in responses:\n",
        "        print(response.text)"
      ],
      "metadata": {
        "id": "QE8GGIYCXY6F"
      },
      "id": "QE8GGIYCXY6F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8u7ylsWxYb70"
      },
      "id": "8u7ylsWxYb70"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Safety Attributes"
      ],
      "metadata": {
        "id": "JTLWMLdTan03"
      },
      "id": "JTLWMLdTan03"
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"max_output_tokens\": 1024,\n",
        "    \"temperature\": 1,\n",
        "    \"top_p\": 1,\n",
        "    \"top_k\": 40\n",
        "}\n",
        "\n",
        "model = TextGenerationModel.from_pretrained(\"text-bison\")\n",
        "\n",
        "response = model.predict(\n",
        "    \"\"\"Tell me a joke about puppies\"\"\",\n",
        "    **parameters\n",
        ")\n",
        "print(response.text)\n",
        "print(response.safety_attributes)\n",
        "print(\"---------------------\")\n",
        "\n",
        "\n",
        "response = model.predict(\n",
        "    \"\"\"Tell me a joke about politics\"\"\",\n",
        "    **parameters\n",
        ")\n",
        "print(response.text)\n",
        "print(response.safety_attributes)"
      ],
      "metadata": {
        "id": "bKqqEaFxYhgW"
      },
      "id": "bKqqEaFxYhgW",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}