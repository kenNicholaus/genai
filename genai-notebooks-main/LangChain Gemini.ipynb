{
  "cells": [
    {
      "cell_type": "code",
      "id": "0XskZcuEO7R2XhJRQdqhhyvn",
      "metadata": {
        "tags": [],
        "id": "0XskZcuEO7R2XhJRQdqhhyvn"
      },
      "source": [
        "! pip install --upgrade google-cloud-aiplatform google-generativeai langchain langchain-google-genai\n",
        "! pip install \"langchain[docarray]\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Restart session"
      ],
      "metadata": {
        "id": "1R4kga-VRa3w"
      },
      "id": "1R4kga-VRa3w"
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "from IPython.display import display\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "id": "lAFRIN1BEWeC"
      },
      "id": "lAFRIN1BEWeC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define project information\n",
        "PROJECT_ID = ! gcloud config get-value project\n",
        "PROJECT_ID = PROJECT_ID[0]\n",
        "LOCATION = \"us-central1\" # @param {type:\"string\"}\n",
        "\n",
        "# define project information manually if the above code didn't work\n",
        "if PROJECT_ID == \"(unset)\":\n",
        "  PROJECT_ID = \"[your-project-id]\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "import vertexai\n",
        "from vertexai.preview.generative_models import (\n",
        "    GenerationConfig,\n",
        "    GenerativeModel,\n",
        "    Image,\n",
        "    Part,\n",
        ")\n",
        "import langchain\n",
        "from langchain.llms import VertexAI\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "\n",
        "# Initialize Vertex AI\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "print(f\"LangChain version: {langchain.__version__}\")\n",
        "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")"
      ],
      "metadata": {
        "id": "OJ3E8F-JGD-3"
      },
      "id": "OJ3E8F-JGD-3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GenerativeModel(\"gemini-pro\")\n",
        "\n",
        "responses = model.generate_content(\"Tell me a funny joke about dogs?\",\n",
        "                                   stream=True)\n",
        "\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ],
      "metadata": {
        "id": "FauOKmQGH5ax"
      },
      "id": "FauOKmQGH5ax",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input an API Key\n",
        "\n",
        "Create this in you project under APIs and Services | Credentials"
      ],
      "metadata": {
        "id": "bl6ZXwgeRkaf"
      },
      "id": "bl6ZXwgeRkaf"
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "# getpass will prompt for an API Key\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Provide your Google API Key\")\n"
      ],
      "metadata": {
        "id": "0H79Nl1oIYTa"
      },
      "id": "0H79Nl1oIYTa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
        "                             temperature=0.7)\n",
        "result = llm.invoke(\"Tell me a funny joke about dogs\")\n",
        "\n",
        "print(result.content)"
      ],
      "metadata": {
        "id": "INtsggWF9ch4"
      },
      "id": "INtsggWF9ch4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Simple Chain"
      ],
      "metadata": {
        "id": "KdkjlDeASAaS"
      },
      "id": "KdkjlDeASAaS"
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"tell me a short joke about {topic}\"\n",
        ")\n",
        "\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "chain = prompt | llm | output_parser\n",
        "\n",
        "chain.invoke({\"topic\": \"space aliens\"})"
      ],
      "metadata": {
        "id": "BfpR2U2LSG3c"
      },
      "id": "BfpR2U2LSG3c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG with Embeddings\n",
        "\n",
        "This uses an in-memory Vector Store."
      ],
      "metadata": {
        "id": "SeLpY5yUTXts"
      },
      "id": "SeLpY5yUTXts"
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install \"langchain[docarray]\""
      ],
      "metadata": {
        "id": "9Kfi7zlxVvNR"
      },
      "id": "9Kfi7zlxVvNR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.vectorstores import DocArrayInMemorySearch\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "\n",
        "# Vector Store takes array of text plpus the embeddings model\n",
        "# as parameters\n",
        "vectorstore = DocArrayInMemorySearch.from_texts(\n",
        "    [\"Why did the cat get kicked out of the restaurant? Because it was not well-mannered.\",\n",
        "     \"Why did the dog go to the park? To chase squirrels and sniff butts!\",\n",
        "     \"Why did the COBOL programmer get lost in the forest? Because he didnâ€™t know how to exit.\",\n",
        "     \"Why did the computer science student get a geometry textbook? To improve his algorithms.\",\n",
        "     \"Why did the basketball player bring a belt to the game? To hold up his shorts!\",\n",
        "     \"Why did the aliens get sent to the principal's office? Because they were from a different planet.\"\n",
        "     ],\n",
        "\n",
        "    embedding=embeddings # passing in the embedder model\n",
        ")\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n"
      ],
      "metadata": {
        "id": "GAmFLbMeTOpl"
      },
      "id": "GAmFLbMeTOpl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retriever.get_relevant_documents(\"Joke about cats\", )\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "id": "tDmwgiz5WKVx"
      },
      "id": "tDmwgiz5WKVx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retriever.get_relevant_documents(\"Joke about programming\", )\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "id": "cPcztRRXWYDC"
      },
      "id": "cPcztRRXWYDC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retriever.get_relevant_documents(\"Tell me a Joke about dogs\", )\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "id": "ynHT65LIxL3S"
      },
      "id": "ynHT65LIxL3S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Modal"
      ],
      "metadata": {
        "id": "cUXqxSBNxZ1m"
      },
      "id": "cUXqxSBNxZ1m"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from IPython.display import Image\n",
        "\n",
        "image_url = \"https://storage.googleapis.com/doug-rehnstrom-public/newyork.JPG\"\n",
        "\n",
        "content = requests.get(image_url).content\n",
        "Image(content,width=600)\n",
        "\n"
      ],
      "metadata": {
        "id": "1Ue_AaX2zKkz"
      },
      "id": "1Ue_AaX2zKkz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro-vision\")\n",
        "\n",
        "# example\n",
        "message = HumanMessage(\n",
        "    content=[\n",
        "        {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": \"What is the location of this picture? Are there and famous landmarks in the picture? How many people live there?\",\n",
        "        },  # You can optionally provide text parts\n",
        "        {\n",
        "            \"type\": \"image_url\",\n",
        "            \"image_url\": image_url\n",
        "         },\n",
        "    ]\n",
        ")\n",
        "\n",
        "llm.invoke([message])"
      ],
      "metadata": {
        "id": "ToQW1H_h11RL"
      },
      "id": "ToQW1H_h11RL",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}